{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0197e598-56df-4fa5-9f87-4f741f9b3ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1998.9056363267816\n",
      "Mean Squared Error: 7405931.618823596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"behavioral_dataset.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Define feature columns and target (risk score)\n",
    "FEATURE_NAMES = [\"mean_dwell\", \"std_dwell\", \"mean_flight\", \"std_flight\", \n",
    "                 \"avg_mouse_speed\", \"tab_switch_count\", \"copy_events\", \n",
    "                 \"paste_events\", \"inactivity_time\"]\n",
    "\n",
    "X = df[FEATURE_NAMES]\n",
    "y = df['label'] * 100  # Convert 0/1 labels to risk scores (0-100)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train an SVR model\n",
    "svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=5)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svr.predict(X_test)\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred)}\")\n",
    "\n",
    "# Save the model and scaler\n",
    "with open(\"svr_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svr, f)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"scaler\": scaler, \"feature_names\": FEATURE_NAMES}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36780c68-2da6-47e4-8458-dcd02cf43a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_score = svr.predict([[19,7,95,90,0,3,2,1,70]])\n",
    "min_risk=0\n",
    "max_risk=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aeb0d47-edc7-42bb-8a0f-518e9ff8fded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          12       0.00      0.00      0.00       0.0\n",
      "          15       0.00      0.00      0.00       1.0\n",
      "          25       0.00      0.00      0.00       0.0\n",
      "          30       0.00      0.00      0.00       1.0\n",
      "          75       0.00      0.00      0.00       1.0\n",
      "          80       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       3.0\n",
      "   macro avg       0.00      0.00      0.00       3.0\n",
      "weighted avg       0.00      0.00      0.00       3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEGHANA M\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MEGHANA M\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MEGHANA M\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MEGHANA M\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MEGHANA M\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MEGHANA M\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"behavioral_dataset.csv\")\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "FEATURE_NAMES = [\"mean_dwell\", \"std_dwell\", \"mean_flight\", \"std_flight\", \n",
    "                 \"avg_mouse_speed\", \"tab_switch_count\", \"copy_events\", \n",
    "                 \"paste_events\", \"inactivity_time\"]\n",
    "\n",
    "X = df[FEATURE_NAMES]\n",
    "y = df['label']  # Keep as binary (0, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train an SVM classifier with probability estimates\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model and scaler\n",
    "with open(\"svm_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svm, f)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"scaler\": scaler, \"feature_names\": FEATURE_NAMES}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d9af2e6-d9fb-4acb-988e-a57fb84d6317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57.3868302])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr=np.array([19,7,25,10,30,3,2,1,70,0])\n",
    "svr.predict([[20,89,100,0,39,9,2,1,70]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0191ee55-bd5e-4b2a-936d-560c18463018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEGHANA M\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 2932.1956 - mae: 43.6184 - val_loss: 2224.6887 - val_mae: 39.7156\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 2925.1953 - mae: 43.5450 - val_loss: 2219.0796 - val_mae: 39.6508\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 2918.3870 - mae: 43.4727 - val_loss: 2213.2522 - val_mae: 39.5830\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 2911.2043 - mae: 43.3987 - val_loss: 2206.7405 - val_mae: 39.5096\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 2904.0603 - mae: 43.3241 - val_loss: 2199.9368 - val_mae: 39.4317\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 2896.6155 - mae: 43.2453 - val_loss: 2192.5918 - val_mae: 39.3463\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 2888.7039 - mae: 43.1628 - val_loss: 2185.0081 - val_mae: 39.2597\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 2880.4888 - mae: 43.0769 - val_loss: 2177.0833 - val_mae: 39.1697\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 2871.9941 - mae: 42.9872 - val_loss: 2168.1794 - val_mae: 39.0735\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 2862.9219 - mae: 42.8928 - val_loss: 2159.0676 - val_mae: 38.9756\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - loss: 2853.2708 - mae: 42.7942 - val_loss: 2150.3606 - val_mae: 38.8792\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 2843.3062 - mae: 42.6931 - val_loss: 2141.6379 - val_mae: 38.7820\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 2833.0310 - mae: 42.5889 - val_loss: 2132.7200 - val_mae: 38.6825\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 2823.0027 - mae: 42.4856 - val_loss: 2123.5605 - val_mae: 38.5802\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - loss: 2812.6641 - mae: 42.3791 - val_loss: 2114.1228 - val_mae: 38.4746\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - loss: 2801.9883 - mae: 42.2691 - val_loss: 2104.3987 - val_mae: 38.3658\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 2790.9841 - mae: 42.1556 - val_loss: 2094.3796 - val_mae: 38.2534\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 2779.6409 - mae: 42.0384 - val_loss: 2084.0537 - val_mae: 38.1374\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 2767.9705 - mae: 41.9180 - val_loss: 2073.2310 - val_mae: 38.0167\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 2755.9197 - mae: 41.7936 - val_loss: 2061.8225 - val_mae: 37.8902\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 2743.4836 - mae: 41.6645 - val_loss: 2050.0449 - val_mae: 37.7594\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 2730.6458 - mae: 41.5306 - val_loss: 2037.9003 - val_mae: 37.6231\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 2717.2542 - mae: 41.3911 - val_loss: 2025.3672 - val_mae: 37.4822\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 2703.3687 - mae: 41.2469 - val_loss: 2012.4443 - val_mae: 37.3364\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 2688.8064 - mae: 41.0965 - val_loss: 1999.0708 - val_mae: 37.1851\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 2673.7375 - mae: 40.9406 - val_loss: 1985.2158 - val_mae: 37.0280\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 2658.1599 - mae: 40.7789 - val_loss: 1970.8970 - val_mae: 36.8653\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 2642.0366 - mae: 40.6111 - val_loss: 1956.0599 - val_mae: 36.6960\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 2625.3823 - mae: 40.4370 - val_loss: 1940.7755 - val_mae: 36.5210\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 2608.2188 - mae: 40.2578 - val_loss: 1925.1539 - val_mae: 36.3419\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 2590.5242 - mae: 40.0731 - val_loss: 1909.0573 - val_mae: 36.1584\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 2572.3152 - mae: 39.8822 - val_loss: 1892.4916 - val_mae: 35.9695\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 2553.5566 - mae: 39.6846 - val_loss: 1875.3451 - val_mae: 35.7736\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 2534.1538 - mae: 39.4793 - val_loss: 1857.6344 - val_mae: 35.5703\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 2514.1477 - mae: 39.2675 - val_loss: 1839.3268 - val_mae: 35.3583\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 2493.4849 - mae: 39.0479 - val_loss: 1820.4269 - val_mae: 35.1384\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 2472.0916 - mae: 38.8197 - val_loss: 1800.9312 - val_mae: 34.9104\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 2449.9963 - mae: 38.5833 - val_loss: 1780.8218 - val_mae: 34.6741\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 2427.1536 - mae: 38.3382 - val_loss: 1760.1781 - val_mae: 34.4301\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 2403.4680 - mae: 38.0838 - val_loss: 1738.9614 - val_mae: 34.1777\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 2379.1355 - mae: 37.8209 - val_loss: 1717.1163 - val_mae: 33.9165\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 2354.1169 - mae: 37.5491 - val_loss: 1694.4672 - val_mae: 33.6448\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 2328.3218 - mae: 37.2676 - val_loss: 1671.1307 - val_mae: 33.3634\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 2301.6819 - mae: 36.9758 - val_loss: 1646.7740 - val_mae: 33.0695\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 2274.2041 - mae: 36.6733 - val_loss: 1621.6324 - val_mae: 32.7647\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - loss: 2245.7393 - mae: 36.3591 - val_loss: 1595.3749 - val_mae: 32.4463\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step - loss: 2215.7844 - mae: 36.0295 - val_loss: 1568.2565 - val_mae: 32.1157\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 2184.5676 - mae: 35.6857 - val_loss: 1540.2822 - val_mae: 31.7727\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 2152.2400 - mae: 35.3284 - val_loss: 1511.4215 - val_mae: 31.4168\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 2118.8928 - mae: 34.9581 - val_loss: 1481.6699 - val_mae: 31.0476\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 2084.6462 - mae: 34.5755 - val_loss: 1451.1285 - val_mae: 30.6655\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 2049.4690 - mae: 34.1800 - val_loss: 1419.8239 - val_mae: 30.2702\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 2013.3650 - mae: 33.7710 - val_loss: 1387.8029 - val_mae: 29.8620\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 1976.3811 - mae: 33.3490 - val_loss: 1355.0845 - val_mae: 29.4408\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1938.3906 - mae: 32.9126 - val_loss: 1321.7043 - val_mae: 29.0065\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 1899.5953 - mae: 32.5522 - val_loss: 1288.1093 - val_mae: 28.5611\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 1859.5471 - mae: 32.1893 - val_loss: 1254.0765 - val_mae: 28.1040\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 1818.5381 - mae: 31.8133 - val_loss: 1218.3463 - val_mae: 27.6231\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 1776.4806 - mae: 31.4232 - val_loss: 1181.9093 - val_mae: 27.1268\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 1733.5106 - mae: 31.0186 - val_loss: 1144.8492 - val_mae: 26.6154\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1689.5526 - mae: 30.6357 - val_loss: 1106.7990 - val_mae: 26.0852\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1644.0974 - mae: 30.3087 - val_loss: 1067.5022 - val_mae: 25.5330\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 1597.2024 - mae: 29.9639 - val_loss: 1027.7343 - val_mae: 24.9657\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - loss: 1549.6681 - mae: 29.6078 - val_loss: 987.4742 - val_mae: 24.3828\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - loss: 1501.3585 - mae: 29.2368 - val_loss: 946.8511 - val_mae: 23.9086\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step - loss: 1452.1163 - mae: 28.8509 - val_loss: 905.9809 - val_mae: 23.5894\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1402.2000 - mae: 28.4493 - val_loss: 864.8548 - val_mae: 23.2530\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 1351.8025 - mae: 28.0311 - val_loss: 823.6922 - val_mae: 22.9025\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1301.0067 - mae: 27.5955 - val_loss: 782.5172 - val_mae: 22.5362\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1249.9939 - mae: 27.1426 - val_loss: 741.5925 - val_mae: 22.1548\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 1198.8956 - mae: 26.6726 - val_loss: 701.0568 - val_mae: 21.7553\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 1147.8207 - mae: 26.1853 - val_loss: 661.0540 - val_mae: 21.3408\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1096.8998 - mae: 25.6812 - val_loss: 621.7132 - val_mae: 20.9106\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 1046.2568 - mae: 25.1601 - val_loss: 583.1608 - val_mae: 20.4639\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 996.0282 - mae: 24.6219 - val_loss: 545.5279 - val_mae: 20.0004\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 946.3588 - mae: 24.0669 - val_loss: 508.9486 - val_mae: 19.5199\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 897.4302 - mae: 23.4979 - val_loss: 473.5309 - val_mae: 19.0218\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 849.4222 - mae: 22.9167 - val_loss: 439.2016 - val_mae: 18.5019\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 802.4135 - mae: 22.3203 - val_loss: 406.2974 - val_mae: 17.9641\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 756.6451 - mae: 21.7137 - val_loss: 374.9845 - val_mae: 17.4097\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 712.2224 - mae: 21.0934 - val_loss: 345.4032 - val_mae: 16.8394\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 669.2274 - mae: 20.4588 - val_loss: 317.6830 - val_mae: 16.2549\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 627.7645 - mae: 19.8102 - val_loss: 291.5080 - val_mae: 15.6456\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 587.5194 - mae: 19.1406 - val_loss: 267.2232 - val_mae: 15.0161\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 548.9864 - mae: 18.4541 - val_loss: 245.1831 - val_mae: 14.3721\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 512.5331 - mae: 17.7556 - val_loss: 225.5602 - val_mae: 13.7164\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - loss: 478.3930 - mae: 17.0480 - val_loss: 208.4874 - val_mae: 13.0518\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 446.7647 - mae: 16.3342 - val_loss: 194.0694 - val_mae: 12.3812\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 417.7964 - mae: 15.6169 - val_loss: 182.3613 - val_mae: 11.7077\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 391.6077 - mae: 14.8990 - val_loss: 173.3776 - val_mae: 11.0346\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 368.2856 - mae: 14.1838 - val_loss: 167.0885 - val_mae: 10.3653\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 347.8701 - mae: 13.5748 - val_loss: 163.4102 - val_mae: 9.7033\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 330.3636 - mae: 13.5716 - val_loss: 162.1687 - val_mae: 9.1168\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 315.7078 - mae: 13.5665 - val_loss: 163.1489 - val_mae: 9.6943\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 303.7954 - mae: 13.5595 - val_loss: 166.2032 - val_mae: 10.2471\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 294.4731 - mae: 13.5507 - val_loss: 171.0592 - val_mae: 10.7716\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 287.5396 - mae: 13.5401 - val_loss: 177.4092 - val_mae: 11.2646\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 282.7505 - mae: 13.5279 - val_loss: 184.9120 - val_mae: 11.7228\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 279.8233 - mae: 13.5140 - val_loss: 193.2062 - val_mae: 12.1431\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 278.4679 - mae: 13.4998 - val_loss: 201.9826 - val_mae: 12.5241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 201.9826 - mae: 12.5241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 12.52405071258545\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"behavioral_dataset.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Define the feature columns\n",
    "FEATURE_NAMES = [\n",
    "    \"mean_dwell\", \"std_dwell\", \"mean_flight\", \"std_flight\", \n",
    "    \"avg_mouse_speed\", \"tab_switch_count\", \"copy_events\", \n",
    "    \"paste_events\", \"inactivity_time\"\n",
    "]\n",
    "\n",
    "# Use continuous risk scores as targets. \n",
    "# Ensure your dataset has a continuous 'risk_score' column in the range 0-100.\n",
    "# If not, you'll need to create such labels.\n",
    "X = df[FEATURE_NAMES]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build a simple feedforward neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Linear output for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=8, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test MAE: {mae}\")\n",
    "# Save the neural network model and scaler\n",
    "model.save(\"nn_model.h5\")\n",
    "with open(\"nn_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"scaler\": scaler, \"feature_names\": FEATURE_NAMES}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "add95f1d-36a7-47c4-aeac-0fa1b48a1ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Risk Score: 94.16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_array = model.predict(np.array([[1,7,9,7,0,3,0,0,0]]))\n",
    "predicted_value = predicted_array[0][0]  # Extract the scalar value\n",
    "\n",
    "risk_score = max(0, min(100, round(predicted_value, 2)))\n",
    "print(\"Risk Score:\", risk_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f109fa83-365e-4b06-83fb-6d941a29a2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    15\n",
       "2    20\n",
       "3    70\n",
       "4    80\n",
       "5    30\n",
       "6    90\n",
       "7    12\n",
       "8    75\n",
       "9    25\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
